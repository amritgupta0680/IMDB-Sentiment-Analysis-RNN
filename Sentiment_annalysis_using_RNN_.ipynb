{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   List itemIMDB dataset (built into Keras)\n",
        "\n",
        "*  Embedding layer to represent words(OHR{voc size}->Padding{max len}->feature representation{dimension}->embedding)\n",
        "\n",
        "*  Simple RNN layer for sequential processing\n",
        "\n",
        "*  Dense layer for classification\n",
        "\n"
      ],
      "metadata": {
        "id": "xhVzsUKeL6nl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USAqlA4SLAsy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use the top 10,000 most frequent words only\n",
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "id": "dXmYkMFJLybl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0],y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaiJeT_tYiwV",
        "outputId": "07d127aa-5116-42a3-902c-7a6bf28e8695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
              "          43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
              "         173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
              "           2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
              "           2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
              "          13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
              "          22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
              "          43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
              "          17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
              "         316,    8,  106,    5,    4, 2223, 5244,   16,  480,   66, 3785,\n",
              "          33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
              "          36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
              "          77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
              "         117, 5952,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
              "          71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
              "        1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
              "          56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
              "         134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,\n",
              "          28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
              "          88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
              "          16, 5345,   19,  178,   32], dtype=int32),\n",
              " np.int64(1))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The IMDB dataset in Keras doesn’t store text reviews as words (like \"This movie is great\"). Instead, it stores them as sequences of integers,\n",
        "where:\n",
        "Each word is replaced by a unique number (index)\n",
        "\n",
        "These numbers are based on word frequency in the dataset"
      ],
      "metadata": {
        "id": "WUsQPadUU8ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Invert the dictionary (integer -> word)\n",
        "index_word = {index + 3: word for word, index in word_index.items()}\n",
        "\n",
        "# Function to decode a review\n",
        "def decode_review(encoded_review):\n",
        "    return ' '.join([index_word.get(i, \"?\") for i in encoded_review])\n",
        "\n",
        "# Print first 2 decoded reviews with labels\n",
        "print(\"Sample Review 1:\")\n",
        "print(decode_review(x_train[0]))\n",
        "print(\"Label:\", y_train[0], \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD5J38w2P8nw",
        "outputId": "b1e20e7c-4803-4c4d-8880-82066bd28565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Review 1:\n",
            "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Label: 1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Pad sequences so that all reviews are the same length (required for RNN input)\n",
        "maxlen = 500  # we'll use only the first 500 words of each review\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n"
      ],
      "metadata": {
        "id": "4_uLaWBkR6Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "id": "h_OGi_YrYyBB",
        "outputId": "2e4329cd-06b8-46a8-f412-2c2e4fdb81c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
              "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
              "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
              "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
              "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
              "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
              "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
              "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
              "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
              "        316,    8,  106,    5,    4, 2223, 5244,   16,  480,   66, 3785,\n",
              "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
              "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
              "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
              "        117, 5952,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
              "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
              "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
              "         56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
              "        134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,\n",
              "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
              "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
              "         16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding layer turns word indices into dense vectors of fixed size\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen))\n",
        "\n",
        "# RNN layer to capture sequential dependencies\n",
        "model.add(SimpleRNN(32))\n",
        "\n",
        "# Output layer: single neuron with sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUVd7xGlSg9z",
        "outputId": "3b8210a8-2dcd-4386-c4ba-d7ee3f1478dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrRNCH7HTLcx",
        "outputId": "e77e97f9-89b9-46f7-e80f-c7d612fdb70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - accuracy: 0.8950 - loss: 0.2597 - val_accuracy: 0.7866 - val_loss: 0.5329\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - accuracy: 0.9520 - loss: 0.1425 - val_accuracy: 0.7612 - val_loss: 0.7201\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.9560 - loss: 0.1250 - val_accuracy: 0.7514 - val_loss: 0.7158\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9834 - loss: 0.0618 - val_accuracy: 0.7736 - val_loss: 0.7492\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.9946 - loss: 0.0249 - val_accuracy: 0.7660 - val_loss: 0.8631\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9964 - loss: 0.0184 - val_accuracy: 0.7510 - val_loss: 0.9915\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9902 - loss: 0.0335 - val_accuracy: 0.7072 - val_loss: 1.1838\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9940 - loss: 0.0207 - val_accuracy: 0.6904 - val_loss: 1.3293\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.9931 - loss: 0.0232 - val_accuracy: 0.7574 - val_loss: 1.0974\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.9984 - loss: 0.0071 - val_accuracy: 0.7800 - val_loss: 1.0745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c503411e190>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"\\nTest Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmYd6ke1TMul",
        "outputId": "60a28426-5e47-43f8-d2b6-1a66d269a337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.7701 - loss: 1.1132\n",
            "\n",
            "Test Accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save my model\n",
        "\n",
        "model.save('imdb_rnn_model.h5')\n",
        "from google.colab import files\n",
        "files.download('imdb_rnn_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "z3ULAFU0WhWL",
        "outputId": "4dd76c22-d8f9-4a53-cb6f-a9871cc9c9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b3645060-21db-43e6-a181-e9e1d27d2b09\", \"imdb_rnn_model.h5\", 3899080)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKL2n_p3WTKD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}